---
layout: single
title: "Gradient Descent Explained"
categories: [Machine Learning]
mathjax: true
---

<!-- <script type="text/javascript" async -->
<!--   src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> -->
<!-- </script> -->

Gradient descent minimizes the loss:

$$
\theta \leftarrow \theta - \eta \nabla_\theta \ell(\theta)
$$
